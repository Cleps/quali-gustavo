\chapter{Trabalhos Relacionados}


No passado, a tarefa de Estimação Monocular de Profundidade não era abordada de forma direta. Um exemplo deste cenário é o trabalho de \citeonline{hoiem2005automatic}, em que o objetivo é reconstruir uma cena 3D em um ambiente virtual através de uma única imagem RGB. Apesar da finalidade não ser a construção de um mapa de profundidade, a reconstrução 3D de uma cena é diretamente ligada à informação de profundidade, portanto, esse trabalho é creditado em revisões bibliográficas do tema \cite{mertan2022single}. É considerado que um ambiente externo consiste de elementos fixos, o céu, um plano de chão e objetos verticais saindo deste plano. É realizada uma classificação de superpixels nas classes através de características pré-selecionadas manualmente, e os objetos são colocados em 3D através das mesmas.


Ainda nos primórdios da MDE, um dos primeiros trabalhos a se propor a estimar um mapa de profundidade métrico de uma única imagem RGB é o de \citeonline{saxena2005learning}. Filtros manualmente projetados são aplicados em pequenos pedaços de uma imagem de entrada para extrair características. Para cada parte, um valor de distância é estimado. Os filtros são então aplicados em múltiplas escalas para levar em consideração as pistas visuais globais e de partes adjacentes. Pesos maiores são atribuidos às características dos pedaços que ficam nas mesmas colunas, baseado na premissa de que as estruturas dos objetos observados são em sua maioria, verticais. Além disso, um modelo baseado em Campos Aleatórios de Markov (\textit{Markov Random Field} - MRF) é treinado de maneira supervisionada para estimar a profundidade a partir das características.


Algum tempo depois, outro trabalho publicado por \citeonline{saxena2008make3d}, adicionou um pressuposto pertinente ao estado da arte de MDE, que uma cena consiste de várias pequenas superfícies planas e a orientação e localização 3D dessa superfície podem ser utilizadas para calcular sua profundidade. Esse pressuposto é utilizado até hoje em motores gráficos que criam modelos de objetos complexos através de malhas triangulares. Novamente, é utilizado um modelo baseado em MRF treinado de maneira supervisionada. As características são obtidas através de filtros manualmente projetados e a contextualização global é considerada através de superpixels adjacentes.


Considerando o desenvolvimento do aprendizado profundo à época, \citeonline{eigen2014depth} introduziu o uso de redes neurais convolucionais para a tarefa de MDE, superando as técnicas anteriores. O problema foi formulado como um método de regressão com aprendizado supervisionado de um conjunto de duas redes neurais. A primeira é responsável por uma estimação grosseira do mapa de profundidade. Sendo composta por camadas convolucionais totalmente conectadas, possui a imagem toda como campo receptivo, utilizando melhor o contexto global, a custo de um grande custo computacional. A segunda rede neural é totalmente convolucional e possui como entrada o mapa da rede anterior, e tem como finalidade o ajuste fino do mapa de profundidade, operando através de filtros locais. Além disso foi utilizada uma função de perda com invariância em escala no espaço logarítmico.

A pesquisa realizada por \citeonline{ranftl2020towards} possui como principal contribuição o desenvolvimento de protocolos de mesclagem de conjuntos de dados de profundidade mesmo que suas anotações não sejam compatíveis. O núcleo dessa abordagem consiste em uma função que é invariante em escala e alcance em um processo de aprendizado multi-objetivo combinando dados de diferentes fontes. A arquitetura da rede consiste em uma estrutura baseada em ResNet em multi escala. Outra contribuição foi o emprego de filmes 3D para composição da base de dados de treinamento em larga escala, apesar de não apresentar anotação de profundidade, foi utilizado \textit{stereo matching} para obtenção do \textit{groundtruth}. 

Em \cite{ke2024repurposing} foi apresentado um protocolo de \textit{fine tuning} de modelos de difusão latente pré-treinados para estimação relativa de profundidade sob qualquer circunstância. O protocolo, chamado de Marigold, contribui com o estado da arte sendo um dos trabalhos que investigou o uso de bases de dados de imagens sintéticas para treinamento, dado que estas não estariam propensas a erros de captura. Utilizou-se um modelo de difusão estável pré-treinado, e o ajuste do modelo é realizado utilizando uma função objetivo calculada no espaço latente entre a saída da U-Net e o ruído inicial. Outra contribuição do trabalho foi a aplicação de ruído rectificado em multi resolução no processo de difusão. 
