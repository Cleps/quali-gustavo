

@article{zhang2022indepth,
  title={Indepth: Real-time depth inpainting for mobile augmented reality},
  author={Zhang, Yunfan and Scargill, Tim and Vaishnav, Ashutosh and Premsankar, Gopika and Di Francesco, Mario and Gorlatova, Maria},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={6},
  number={1},
  pages={1--25},
  year={2022},
  publisher={ACM New York, NY, USA}
}

@article{wu2022joint,
  title={Joint self-supervised and reference-guided learning for depth inpainting},
  author={Wu, Heng and Fu, Kui and Zhao, Yifan and Song, Haokun and Li, Jia},
  journal={Computational Visual Media},
  volume={8},
  number={4},
  pages={597--612},
  year={2022},
  publisher={Springer}
}

@inproceedings{castellano2023performance,
  title={Performance Evaluation of Depth Completion Neural Networks for Various RGB-D Camera Technologies in Indoor Scenarios},
  author={Castellano, Rino and Terreran, Matteo and Ghidoni, Stefano},
  booktitle={International Conference of the Italian Association for Artificial Intelligence},
  pages={351--364},
  year={2023},
  organization={Springer}
}

@article{eigen2014depth,
  title={Depth map prediction from a single image using a multi-scale deep network},
  author={Eigen, David and Puhrsch, Christian and Fergus, Rob},
  journal={Advances in neural information processing systems},
  volume={27},
  year={2014}
}

@article{dourado2020multi,
  title={Multi-objective cartesian genetic programming optimization of morphological filters in navigation systems for visually impaired people},
  author={Dourado, Antonio Miguel Batista and Pedrino, Emerson Carlos},
  journal={Applied Soft Computing},
  volume={89},
  pages={106130},
  year={2020},
  publisher={Elsevier}
}

@article{hu2022deep,
  title={Deep depth completion from extremely sparse data: A survey},
  author={Hu, Junjie and Bao, Chenyu and Ozay, Mete and Fan, Chenyou and Gao, Qing and Liu, Honghai and Lam, Tin Lun},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume={45},
  number={7},
  pages={8244--8264},
  year={2022},
  publisher={IEEE}
}

@article{lasinger2019towards,
  title={Towards robust monocular depth estimation: Mixing datasets for zero-shot cross-dataset transfer},
  author={Lasinger, Katrin and Ranftl, Ren{\'e} and Schindler, Konrad and Koltun, Vladlen},
  journal={arXiv preprint arXiv:1907.01341},
  year={2019}
}

@article{zhou2019does,
  title={Does computer vision matter for action?},
  author={Zhou, Brady and Kr{\"a}henb{\"u}hl, Philipp and Koltun, Vladlen},
  journal={Science Robotics},
  volume={4},
  number={30},
  pages={eaaw6661},
  year={2019},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{jaritz2018sparse,
  title={Sparse and dense data with cnns: Depth completion and semantic segmentation},
  author={Jaritz, Maximilian and De Charette, Raoul and Wirbel, Emilie and Perrotton, Xavier and Nashashibi, Fawzi},
  booktitle={2018 International Conference on 3D Vision (3DV)},
  pages={52--60},
  year={2018},
  organization={IEEE}
}

@article{song2021self,
  title={Self-supervised depth completion from direct visual-lidar odometry in autonomous driving},
  author={Song, Zhenbo and Lu, Jianfeng and Yao, Yazhou and Zhang, Jian},
  journal={IEEE Transactions on Intelligent Transportation Systems},
  volume={23},
  number={8},
  pages={11654--11665},
  year={2021},
  publisher={IEEE}
}

@article{ma2019sparse,
  title={Sparse depth sensing for resource-constrained robots},
  author={Ma, Fangchang and Carlone, Luca and Ayaz, Ulas and Karaman, Sertac},
  journal={The International Journal of Robotics Research},
  volume={38},
  number={8},
  pages={935--980},
  year={2019},
  publisher={SAGE Publications Sage UK: London, England}
}

@article{teixeira2020aerial,
  title={Aerial single-view depth completion with image-guided uncertainty estimation},
  author={Teixeira, Lucas and Oswald, Martin R and Pollefeys, Marc and Chli, Margarita},
  journal={IEEE Robotics and Automation Letters},
  volume={5},
  number={2},
  pages={1055--1062},
  year={2020},
  publisher={IEEE}
}

@inproceedings{farkhani2019sparse,
  title={Sparse-to-dense depth completion in precision farming},
  author={Farkhani, Sadaf and Kragh, Mikkel Fly and Christiansen, Peter Hviid and J{\o}rgensen, Rasmus Nyholm and Karstoft, Henrik},
  booktitle={Proceedings of the 3rd International Conference on Vision, Image and Signal Processing},
  pages={1--5},
  year={2019}
}

@inproceedings{du2020depthlab,
  title={DepthLab: Real-time 3D interaction with depth maps for mobile augmented reality},
  author={Du, Ruofei and Turner, Eric and Dzitsiuk, Maksym and Prasso, Luca and Duarte, Ivo and Dourgarian, Jason and Afonso, Joao and Pascoal, Jose and Gladstone, Josh and Cruces, Nuno and others},
  booktitle={Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology},
  pages={829--843},
  year={2020}
}

@article{padhy2023monocular,
  title={Monocular Vision-aided Depth Measurement from RGB Images for Autonomous UAV Navigation},
  author={Padhy, Ram Prasad and Sa, Pankaj Kumar and Narducci, Fabio and Bisogni, Carmen and Bakshi, Sambit},
  journal={ACM Transactions on Multimedia Computing, Communications and Applications},
  volume={20},
  number={2},
  pages={1--22},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{hu2012robust,
  title={A robust rgb-d slam algorithm},
  author={Hu, Gibson and Huang, Shoudong and Zhao, Liang and Alempijevic, Alen and Dissanayake, Gamini},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={1714--1719},
  year={2012},
  organization={IEEE}
}

@misc{branscombe2018microsoft,
  title={How Microsoft is making its most sensitive HoloLens depth sensor yet},
  author={Branscombe, Mary},
  year={2018},
  note= {\url{https://www.zdnet.com/article/how-microsoft-is-making-its-most-sensitive-hololens-depth-sensor-yet/} }
}


@book{szeliski2022computer,
  title={Computer vision: algorithms and applications},
  author={Szeliski, Richard},
  year={2022},
  publisher={Springer Nature}
}

@inproceedings{zhang2018deep,
  title={Deep depth completion of a single rgb-d image},
  author={Zhang, Yinda and Funkhouser, Thomas},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={175--185},
  year={2018}
}

@inproceedings{xie2021ultradepth,
  title={UltraDepth: Exposing high-resolution texture from depth cameras},
  author={Xie, Zhiyuan and Ouyang, Xiaomin and Liu, Xiaoming and Xing, Guoliang},
  booktitle={Proceedings of the 19th ACM Conference on Embedded Networked Sensor Systems},
  pages={302--315},
  year={2021}
}

@book{hansard2012time,
  title={Time-of-flight cameras: principles, methods and applications},
  author={Hansard, Miles and Lee, Seungkyu and Choi, Ouk and Horaud, Radu Patrice},
  year={2012},
  publisher={Springer Science \& Business Media}
}

@misc{instruments2019introduction,
  title={Introduction to time-of-flight long range proximity and distance sensor system design (Rev. B)},
  author={Instruments, Texas},
  year={2019}
}

@article{zollhofer2019commodity,
  title={Commodity RGB-D sensors: Data acquisition},
  author={Zollh{\"o}fer, Michael},
  journal={RGB-D image analysis and processing},
  pages={3--13},
  year={2019},
  publisher={Springer}
}

@article{park2021enabling,
  title={Enabling real-time sign language translation on mobile platforms with on-board depth cameras},
  author={Park, HyeonJung and Lee, Youngki and Ko, JeongGil},
  journal={Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies},
  volume={5},
  number={2},
  pages={1--30},
  year={2021},
  publisher={ACM New York, NY, USA}
}

@article{see2022smartphone,
  title={A smartphone-based mobility assistant using depth imaging for visually impaired and blind},
  author={See, Aaron Raymond and Sasing, Bien Grenier and Advincula, Welsey Daniel},
  journal={Applied Sciences},
  volume={12},
  number={6},
  pages={2802},
  year={2022},
  publisher={MDPI}
}

@article{do2023real,
  title={Real-Time Hole-Filling in Mobile Augmented Reality Gaming: A Novel Algorithm to Overcome Depth Sensor Limitations},
  author={Do Heon Choi, Seok-Kyoo Kim and Kim, SeongKi},
  journal={Traitement du Signal},
  volume={40},
  number={4},
  pages={1377--1384},
  year={2023}
}

@inproceedings{suvorov2022resolution,
  title={Resolution-robust large mask inpainting with fourier convolutions},
  author={Suvorov, Roman and Logacheva, Elizaveta and Mashikhin, Anton and Remizova, Anastasia and Ashukha, Arsenii and Silvestrov, Aleksei and Kong, Naejin and Goka, Harshith and Park, Kiwoong and Lempitsky, Victor},
  booktitle={Proceedings of the IEEE/CVF winter conference on applications of computer vision},
  pages={2149--2159},
  year={2022}
}

@article{elharrouss2020image,
  title={Image inpainting: A review},
  author={Elharrouss, Omar and Almaadeed, Noor and Al-Maadeed, Somaya and Akbari, Younes},
  journal={Neural Processing Letters},
  volume={51},
  pages={2007--2028},
  year={2020},
  publisher={Springer}
}

@article{luo2016understanding,
  title={Understanding the effective receptive field in deep convolutional neural networks},
  author={Luo, Wenjie and Li, Yujia and Urtasun, Raquel and Zemel, Richard},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016}
}

@inproceedings{roberts2021hypersim,
  title={Hypersim: A photorealistic synthetic dataset for holistic indoor scene understanding},
  author={Roberts, Mike and Ramapuram, Jason and Ranjan, Anurag and Kumar, Atulit and Bautista, Miguel Angel and Paczan, Nathan and Webb, Russ and Susskind, Joshua M},
  booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
  pages={10912--10922},
  year={2021}
}

@inproceedings{liu2012guided,
  title={Guided inpainting and filtering for kinect depth maps},
  author={Liu, Junyi and Gong, Xiaojin and Liu, Jilin},
  booktitle={Proceedings of the 21st International Conference on Pattern Recognition (ICPR2012)},
  pages={2055--2058},
  year={2012},
  organization={IEEE}
}